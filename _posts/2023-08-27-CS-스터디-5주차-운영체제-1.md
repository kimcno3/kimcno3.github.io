---
layout: post
categories: CS
tags: CS
title: "[CS 스터디] 운영체제 1"
---
## 0. 시작 전에, 운영체제란?
> [참고 자료](https://velog.io/@nnnyeong/OS-%EC%9A%B4%EC%98%81%EC%B2%B4%EC%A0%9C-Operating-System)

운영체제란 하드웨어와 응용 프로그램 사이에 위치하여 하드웨어를 관리하고 시스템의 동작을 제어하는 시스템 소프트웨어를 말합니다. 
사용하는 주 목적은 CPU, 메모리, 디스크 등의 하드웨어를 효율적으로 관리하기 위함입니다. 
운영체제란 결국, **컴퓨터의 성능을 높이면서 사용자의 편의를 제공하는 목적으로 사용되는 컴퓨터 하드웨어 관리 프로그램**입니다.

> OS는 그러면 어디에 존재할까? 
>  - OS는 유저 프로세스 안에서 조금씩 포함되어서 동작한다.
>
> OS는 프로세스일까요?
>  - 프로세스 일수도 아닐 수도 있다.
>  - 이는 OS 자체가 프로세스라고 볼 수 힘들지만 모든 프로세스에 숨어서 동작하기 때문에 온전히 프로세스가 아니다라고도 볼 수 없습니다.

### 운영체제 구조
- 쉘 : 사용자가 커널에 보내고자 하는 명령어를 해석해 실제로 커널에 전달해주는 역할을 합니다.
- 커널 : 운영체제가 관리하고 동작하는 모든 내용을 담당하며 항상 메모리에 상주해 있습니다.

> 운영체제의 생명 주기는 컴퓨터와 동일하게 가져갑니다.

### 운영체제의 업무
- 프로세스 관리
  - 현재 CPU가 점유해야 할 프로세스 지정
  - CPU를 프로세스에 할당
  - 프로세스 간 공유자원 접근 및 관리
  - 즉, 프로세스, 쓰레드, 스케줄링 등을 관리합니다.
- 메모리 관리
  - 프로세스를 작업하는 과정에서 발생하는 메모리에 대한 할당 및 저장 관리를 합니다.
- 네트워킹
  - 네트워크를 통해 외부와 연결하고자 할 때, 네트워크 프로토콜을 지원합니다.
  - 인터넷을 위한 TCP/IP와 같은 내용이 포함됩니다.
- 사용자 관리
  - 파일이나 시스템 자원에 대한 접근 권한을 사용자 별로 상이하게 관리될 수 있도록 합니다.
- 디바이스 드라이버
  - 여러 물리적인 장치들과 연결해 동작할 수 있도록 기능을 제공합니다.

## 1. 시스템 콜이 무엇인지 설명해 주세요.
- 시스템 콜이란 사용자 프로그램이 운영체제의 기능을 사용하기 위해 호출하는 인터페이스입니다.
- 시스템 콜이 사용될 때에는 사용자 모드에서 커널 모드로 전환되어 동작합니다.

### 우리가 사용하는 시스템 콜의 예시를 들어주세요.
- 여러 리눅스 명령어들은 시스템 콜과 직접적인 연관이 있으며 해당 명령어들을 통해 시스템 콜을 호출할 수 있습니다.

- 프로세스 제어(System Control):
  - fork(): 새로운 자식 프로세스 생성.
  - **exec(): 새로운 프로그램 실행.**
  - wait(): 자식 프로세스의 종료를 기다림.

- 파일 관리(File Management):
  - open(): 파일 열기.
  - read(): 파일에서 데이터 읽기.
  - write(): 파일에 데이터 쓰기.
  - close(): 파일 닫기.
  
- 메모리 관리(Memory Management):
  - malloc(): 동적으로 메모리 할당.
  - free(): 동적으로 할당된 메모리 해제.

- 장치 관리(Device Management):
  - read(), write(): 장치 드라이버를 통한 입출력.
  - ioctl(): 장치에 대한 제어 명령 전송.

- 통신(Communication):
  - socket(): 네트워크 소켓 생성.
  - bind(), connect(): 소켓에 주소 연결 및 연결 요청.
  - send(), recv(): 데이터 송수신.

- 파일 시스템 관리(File System Management):
  - **mkdir(): 디렉토리 생성.**
  - **rmdir(): 디렉토리 삭제.**
  - stat(): 파일의 메타데이터 조회.

- 시그널 관리(Signal Management):
  - **kill(): 프로세스나 그룹에 시그널 보내기.**
  - signal(): 시그널 핸들러 설정.

- 시간(Time):
  - time(): 현재 시간 조회.
  - sleep(): 프로세스 일시 정지.

- 보안 및 권한 관리(Security and Permission):
  - **chmod(): 파일의 권한 변경.**
  - chown(): 파일의 소유자 변경.
  
- 프로세스 간 통신(Interprocess Communication):
  - pipe(): 파이프 생성.
  - msgget(), msgrcv(), msgsnd(): 메시지 큐 조작.
  - shmget(), shmat(), shmdt(): 공유 메모리 조작.

### 시스템 콜이, 운영체제에서 어떤 과정으로 실행되는지 설명해 주세요.
![](https://velog.velcdn.com/images/nnnyeong/post/5ffac049-22e2-486e-8d4d-11f7f0d31778/image.png)
1. 프로세스가 System Call을 호출하면 trap이 발생하여 kernel mode로 진입
2. 요청이 들어온 System Call을 수행
3. return-from-trap을 발생시켜 user mode로 돌아간다.

> 트랩은 시스템 콜 연산을 발생시키는 것을 의미합니다.

### 시스템 콜의 유형에 대해 설명해 주세요.
- 프로세스 제어
  - 프로세스 생성 및 종료
  - 메모리에 로드, 실행
  - 프로세스 속성 값 확인, 지정
  - wait 이벤트, signal 이벤트
  - 메모리 할당
- 파일 관리
  - 파일 생성, 파일 삭제
  - 열기, 닫기
  - 읽기, 쓰기, Reposition
  - 파일 속성 값 확인, 지정
- 통신
  - 커뮤니케이션 연결 생성 및 삭제
  - 메시지 송신, 수신
  - 상태 정보 전달
  - remote 디바이스 해제 및 장착
- 장치 관리
  - 디바이스 요청 및 해제
  - 읽기, 쓰기, Reposition
  - 디바이스 속성 확인, 지정
  - 비 물리적인 디바이스 해제 및 장착

### 운영체제의 Dual Mode 에 대해 설명해 주세요.
- 사용자 모드와 커널 모드라는 두개의 다른 권한을 가진 형태로 구분하는 것을 의미합니다.
- 두 권한의 차이를 통해 의도나 목적에 따라 모드를 변경하고 유지할 수 있습니다.

### 왜 유저모드와 커널모드를 구분해야 하나요?
- 가장 큰 이유는 보안적인 측면입니다.
- 사용자 모드에서 사용자가 응용 프로그램을 사용하면서 제공되어야 할 최소한의 권한을 부여함으로써 운영 체제의 관리 범위에서 직접적인 영향을 주는 것을 피할 수 있습니다.
- 이에 반해 커널 모드에선 운영체제의 권한에 대한 접근을 허용해 실제 시스템 콜이 호출 되었을 때 해당 내용을 처리해줄 수 있도록 할 수 있습니다.
- 결국, 중요도와 위험도에 따라 모드를 다르게 해 더 안정적인 운영이 가능한 구조로 설계하기 위함입니다.

### 서로 다른 시스템 콜을 어떻게 구분할 수 있을까요?
- 커널은 내부적으로 시스템 콜의 구분을 위해 기능 별 고유번호를 할당한 것으로 알고 있습니다.
- 이 고유번호를 가지고 해당하는 호출될 함수를 결정합니다.

## 2. 인터럽트가 무엇인지 설명해 주세요.
- 인터럽트는 현재 실행 중인 프로세스나 작업을 중단하고 특정한 처리를 수행하기 위해 CPU의 제어를 전환시키는 메커니즘입니다.

### 인터럽트는 어떻게 처리하나요?
1. 인터럽트 요청
2. 프로그램 실행 중단
   - 현재 실행중이던 Micro Operation 까지 수행
3. 현재 실행중인 프로그램 상태 보관
   - Interrupt Vector 를 읽어 ISR 주소값을 얻는다.
   - ISR 로 점프한다.
   - 이 때, PC 값은 자동 대피 저장하고 현재 진행중인 프로그램의 레지스터를 대피
4. 인터럽트 서비스 루틴 처리
   - 인터럽트 원인을 파악하고 실질적인 작업 수행
   - 서비스 루틴 수행 중, 우선순위가 더 높은 인터럽트가 발생하면 재귀적으로 1~5 과정 수행
5. 상태 복구
   - 해당 작업을 다 처리하면, 대피시킨 레지스터를 복원한다
   - ISR 끝에 RETI 명령어에 의해 인터럽트 해제
   - 명령어가 실행되면, PC 값을 복원하여 이전 실행 위치로 복원

> **PC(Program Counter)** : CPU 내부에 있는 레지스터 중의 하나로서, 다음에 실행될 프로그램 내의 명령어의 주소를 가지고 있어 실행할 기계어 코드의 위치를 지정한다. 때문에 명령어 포인터라고도 불린다.
> 
> **인터럽트 핸들러** : ISR(Interrupt Service Routine)은 인터럽트가 발생했을 때 실행되는 함수 또는 서브루틴으로, 해당 인터럽트의 처리를 담당하는 코드 블록입니다.
> 
> **인터럽트 벡터** : 인터럽트 발생 시 처리해야 할 ISR 주소를 보관하고 있는 테이블

### Polling 방식에 대해 설명해 주세요.
- 높은 순위의 인터럽트부터 시스템에서 외부 장치나 상태를 주기적으로 확인 및 조사 하고, 이상이 발생하는 경우 이벤트로 인식하고 처리해주는 방식을 의미합니다.
- 직관적이고 단순한 형태로 동작하지만 그 만큼 비동기적으로 지속적인 동작이 반복해 리소스의 낭비가 인터럽트에 비해 심하다고 할 수 있습니다.

### HW / SW 인터럽트에 대해 설명해 주세요.
- 하드웨어(HW) 인터럽트
  - 하드웨어 장치에서 발생하는 인터럽트로, 외부 장치에서의 신호나 이벤트에 의해 발생합니다. 
  - 예를 들어, 키보드의 키를 누르거나 마우스를 클릭하는 경우가 하드웨어 인터럽트의 예입니다.
  - 또는 정전과 전원 이상, 기계 고장과 같은 오류로 인한 인터럽트도 포함됩니다.
- 소프트웨어(SW) 인터럽트
  - 소프트웨어 명령에 의해 발생하는 인터럽트로, 주로 프로그램 실행 도중 명령어에 의해 발생합니다. 
  - 예를 들어, 프로세스가 시스템 호출을 하거나 예외 상황(0으로 나누기 등)이 발생하는 경우가 소프트웨어 인터럽트의 예입니다.

### 동시에 두 개 이상의 인터럽트가 발생하면, 어떻게 처리해야 하나요?
- 인터럽트의 우선순위에 따라 처리됩니다.
- 구체적인 우선 순위는 다음과 같습니다. 
  - 정전•전원이상 인터럽트 > 기계고장 인터럽트 > 외부 인터럽트 > 입출력 인터럽트 > 프로그램 검사 인터럽트 > SVC(SuperVisor Call)

> Nested 방식이라는게 있나

## 3. 프로세스가 무엇인가요?
- 운영체제가 프로그램을 실질적으로 동작하기 위해 필요한 단위로써 하나의 인스턴트로 볼 수 있습니다.
- 즉 프로그램을 실행시키면 CPU를 차지해 프로그램을 요청에 따라 동작시키는 녀석이 프로세스입니다.
- 프로세스는 고유의 PID를 가지며 운영체제에 의해 메모리를 할당받아 동작합니다.

### 프로그램과 프로세스, 스레드의 차이에 대해 설명해 주세요.
- 프로그램 : 파일 시스템에 존재하는 실행파일 과 기타 여러 파일들의 모음
- 프로세스 : 이러한 파일 모음인 프로그램을 운영체제 위에서 실행하고 동작시키는 객체
- 쓰레드 : 프로세스 내에서 나뉘는 작업 단위로서 프로세스의 자원을 공유합니다.

### PCB가 무엇인가요?
> [참고자료](https://jhnyang.tistory.com/6)
>
> [참고자료](https://jwprogramming.tistory.com/16)

- 프로세스마다 마다 현재 상태를 하나의 데이터 구조에 저장하여 관리하는데, 이를 Process Control Block(PCB)라고 부릅니다.
- PCB는 다른 프로세스들이 쉽게 접근할 수 없으며 커널 영역에서 관리합니다.

> PCB는 이미지, 프로세스 컨텍스트로 나뉘며 상세 내용에 대해서 좀 더 알아보기.
> - PCB의 구성요소는 프로세스의 구성요소와 동일하다. 프로세스에 대한 정보를 표현하기 위해서
> - 

### 그렇다면, 스레드는 PCB를 갖고 있을까요?
> [참고자료](https://eunajung01.tistory.com/55)

- 독립적인 PCB를 가지지는 않습니다. PCB는 프로세스 단위로 생성 및 관리되기 때문입니다.
- 하지만 PCB 내에서 TCB 영역에 쓰레드 별로 생성되어 관리될 수 있습니다.
![](https://blog.kakaocdn.net/dn/pouij/btrHaUySUkZ/22UlS0GsFh6QBaRKgcGUTk/img.png)

### 리눅스에서, 프로세스와 스레드는 각각 어떻게 생성될까요?
- 프로세스 생성 명렁어
  - **system()**
    - 프로그램 안에 새로운 프로그램을 생성하며 이 과정에서 프로세스가 생성될 수 있습니다.
    - 쉘에 직접 요청을 보내고 응답을 기다렸다 생성하게 되므로 비효율적입니다.
  - **fork()**
    - 부모 프로세스에서 실행되면 자식 프로세스를 생성합니다.
    - 생성이 되면 두 프로세스는 동시에 동작하게 됩니다.
  - **exec()**
    - 새로운 프로세스를 기존 프로세스의 메모리 공간에 덮어 씌우는 형태로 동작합니다.

- 스레드 생성 명렁어
  - **pthread_create()**
    - 해당 명령어를 통해 스레드를 새로 생성할 수 있으며 인자는 4가지입니다.
    - **thread**: 생성된 스레드의 식별자를 저장할 변수의 포인터입니다.
    - **attr**: 스레드의 특성을 정의하는 속성을 나타내는 포인터입니다. 보통 NULL로 설정하면 기본 속성이 사용됩니다.
    - **start_routine**: 생성된 스레드가 실행할 함수의 포인터입니다. 이 함수는 void * 타입의 인자를 받아 스레드의 작업을 수행하고 void * 타입의 결과를 반환합니다.
    - **arg**: start_routine 함수에 전달되는 인자입니다.
    
### 자식 프로세스가 상태를 알리지 않고 죽거나, 부모 프로세스가 먼저 죽게 되면 어떻게 처리하나요?
> [참고 자료 1](https://codetravel.tistory.com/31)
> 
> [참고 자료 2](https://colinch4.github.io/2021-06-11/wait_waitpid/)

- 자식 프로세스가 상태를 알지 못하고 종료될 경우, 부모 프로세스에서 종료 여부를 알지 못한다면 메모리에 그대로 프로세스가 존재하면서 부모 프로세스가 종료될 때까지 사라지지 않게 됩니다.(= 좀비 프로세스)
- 이러한 경우는 wait() 시스템 콜을 통해 해결해볼 수 있습니다.
- wait() 시스템 콜은 부모 프로세스가 자식 프로세스의 종료를 확인할 때까지 대기하는 함수이며 이를 통해 자식 프로세스가 종료 사실을 알리지 못하는 경우를 방지할 수 있습니다.
- 다만 이러한 경우, 자식 프로세스가 종료될 때까지 부모 프로세스는 다른 작업을 처리하지 못하므로 자식 프로세스에서 종료 시 시그널을 보내 wait() 함수를 호출하도록 구현할 수 있습니다.

- 반대로 부모 프로세스가 먼저 죽는 경우, 남은 자식 프로세스는 고아 프로세스라고 합니다.
- 이런 경우, init 프로세스가 새로운 부모 프로세스로 지정되며 자식 프로세스의 종료에 대한 책임을 가지도록 동작합니다.

### 리눅스에서, 데몬프로세스에 대해 설명해 주세요.
> [참고 자료](https://inpa.tistory.com/entry/%ED%94%84%EB%A1%9C%EC%84%B8%EC%8A%A4-%EB%8D%B0%EB%AA%AC-%EC%84%9C%EB%B9%84%EC%8A%A4-%EC%A0%95%EB%A6%AC)

- 사용자가 직접 제어하지 않고 백그라운드에서 대기하면서 요청이 들어올 때 적절한 처리를 해주는 프로세스를 의미합니다.
- 리눅스에서 대부분 끝자리에 `d`가 붙은 프로세스들이 데몬프로세스라고 볼 수 있습니다.
  - sshd : 암호화 원격 작업
  - vsftpd : FTP, 파일 전송 작업
  - httpd : 브라우저를 통해 웹문서 페이지 출력 작업
  - mysqld : DB 관리 작업
  - sendmail : 메일 전송 작업
- 시스템 부팅 과정이나 무중단 서비스에 경우 사용됩니다.
- 대부분 init 프로세스의 자식 프로세스로 존재합니다.
- 보안성과 안정성에 주의

## 4. 프로세스 주소공간에 대해 설명해 주세요.
> [참고 자료](https://velog.io/@klloo/%EC%9A%B4%EC%98%81%EC%B2%B4%EC%A0%9C-%ED%94%84%EB%A1%9C%EC%84%B8%EC%8A%A4-%EC%A3%BC%EC%86%8C%EA%B3%B5%EA%B0%84)

- **Stack 영역**
  - 함수의 호출과 관계되는 지역 변수와 매개변수가 저장되는 영역입니다.
  - 재귀 함수가 너무 깊게 호출되거나 함수가 지역변수를 너무 많이 가지고 있어 stack 영역을 초과하면 stack overflow 에러가 발생할 수 있어 주의해야 합니다.
- **Heap 영역**
  - 주로 참조형 데이터 (ex. 클래스) 등의 데이터가 할당되며 런타임에 크기가 결정되는 영역입니다.
- **Data 영역**
  - 전역 변수나 Static 변수 등 프로그램이 사용할 수 있는 데이터를 저장하는 영역이다.
  - 프로그램의 시작과 함께 할당되며, 프로그램이 종료되면 소멸한다.
- **Text (Code) 영역**
  - 프로그램이 실행될 수 있도록 CPU가 해석 가능한 기계어 코드가 저장되어 있는 공간으로, 프로그램이 수정되면 안 되므로 ReadOnly 상태로 저장 되어있다.

> Optional한 영역도 존재한다.

### 초기화 하지 않은 변수들은 어디에 저장될까요?
- BSS(Block Stated Symbol) 영역에 저장됩니다.
- 초기화 된 전역 변수들은 데이터 영역에 그렇지 않은 전역 변수들은 BSS 영역에서 관리하게 됩니다.
- 이후 초기화가 된다면 데이터 영역으로 이동합니다.

### 일반적인 주소공간 그림처럼, Stack과 Heap의 크기는 매우 크다고 할 수 있을까요? 그렇지 않다면, 그 크기는 언제 결정될까요?
- 우선 두 영역은 사실 같은 메모리 공간을 공유하며 주소 기준으로 Stack은 위에서 아래로, Heap은 아래에서 위로 메모리를 할당합니다.
- 컴파일 단계에서는 정적으로 영역이 정해지며 스택은 한계 영역이 있습니다.
- 두 메모리의 크기는 매우 크다고 할 수 없습니다. 때에 따라서는 메모리의 크기 이상으로 필요한 경우가 생길 수 있습니다.
- 그렇기에 두 영역의 크기는 동적으로 변경이 가능합니다.
- 즉, 런타임 단계에서 필요에 따라 메모리를 늘릴수도, 줄일수도 있으며 유연한 형태로 요구사항에 따라 메모리를 활용할 수 있습니다.

> 그림마다 스택, 힙 저장 방향이 다른 경우도 있다.
> 
> 

### Stack과 Heap 공간에 대해, 접근 속도가 더 빠른 공간은 어디일까요?
- Stack 영역이라고 할 수 있습니다.
- Stack의 경우, 함수의 흐름을 관리하기 때문에 접근할 수 있는 변수의 공간이 제한적입니다.
- 하지만 Heap의 경우 상대적으로 메모리 할당 및 삭제의 작업이 빈번하게 발생하며 제한적이지 않기 때문에 접근을 위해 조회해야 할 메모리 공간이 넓을 수 있습니다.

### 다음과 같이 공간을 분할하는 이유가 있을까요?
- 역할의 분리를 통해 메모리 공간을 **효율적**으로 사용하기 위함이 있습니다.
  - 필요성에 따라 메모리 할당량을 구분해 제공 및 설계
  - Heap이나 Data 영역에 데이터를 저장함으로써 여러 스레드에서 공유
- 또한 역할에 따라 메모리를 분리했기 때문에 다른 영역에 대한 접근을 제한둠으로써 **안정성**을 확보할 수 있습니다.

### 스레드의 주소공간은 어떻게 구성되어 있을까요?
- Stack 영역만을 별도의 공간으로 가지며 이 외 다른 공간은 하나의 프로세스 내에서 공유합니다.
- 이는 스레드 별로 수행하는 함수의 흐름을 별도로 관리하기 위함입니다.

> 좀 더 구체적인 구분된 명칭을 조사 필요

### "스택"영역과 "힙"영역은 정말 자료구조의 스택/힙과 연관이 있는 걸까요? 만약 그렇다면, 각 주소공간의 동작과정과 연계해서 설명해 주세요.
- 스택 영역의 경우 자료구조 스택과 동일한게 선입후출 방식으로 동작합니다.
- 이는 함수의 동작 흐름이 가장 마지막에 호출된 함수부터 처리해야 하기 때문이고 이러한 방식에서 불필요한 메모리 공개를 제한하기 위함입니다.
- 하지만 힙 영역의 경우, 완전 이진 트리 구조인 힙 구조와는 연관이 없습니다.
- 데이터가 추가될 때마다 힙정렬을 하지 않고 데이터를 저장하고 관리하며 메모리 공간은 동적으로 변하는 방식입니다.

> 스택 영역은 컴파일 단계에서 고정된다? 힙영역은 동적관리가 된다?

### IPC의 Shared Memory 기법은 프로세스 주소공간의 어디에 들어가나요? 그런 이유가 있을까요?
> [참고 자료](https://devraphy.tistory.com/171)
> 
> [참고 자료](https://doitnow-man.tistory.com/68)

- IPC(Inner Process Communication)란 CPU의 개수가 늘어나고 여러 프로세스를 동시가 실행하는 환경에서 프로세스 간의 데이터 공유를 위한 목적으로 사용되는 기법입니다.
- 이는 프로세스간의 상태를 확인하기 위함의 목적이 있다고 볼 수 있습니다.
- 그 중 Shared Memory 기법은 커널 영역에 별도의 메모리 공간을 할당하고 키를 부여해 키를 통해 여러 프로세스가 하나의 데이터에 접근하고 공유가 되도록 하는 방식을 의미합니다.
- Shared Memory는 커널에서 관리하며 별도의 메모리 공간을 가집니다. 그리고 각 프로세스들은 이 메모리를 바라보고 있을 별도의 메모리 공간을 할당해야 합니다.
- 이는 프로세스 내에서 텍스트 영역과 데이터 영역 사이에 저장됩니다.
- 또한 Shared Memory에 저장되는 데이터 또한 static한 성격을 가집니다. 이는 다른 프로세스에서 접근이 용이하고 관리가 편리해야 하는데 그러기 위해선 정적으로 메모리를 할당받고 변하지 않는 두 영역 사이가 적합하기 때문입니다.

> JVM와 프로세스 주소 공간은 별도로 할당되는가?
> - 프로세스가 할당방은 메모리 영역을 JVM이 독립적인 환경으로 구성해 사용하는 것이 맞다고 볼 수 있습니다.

## 5. 단기, 중기, 장기 스케쥴러에 대해 설명해 주세요.
> [참고 자료](https://kosaf04pyh.tistory.com/191#%EC%A-%--%EA%B-%B-%--%EC%-A%A-%EC%BC%--%EC%A-%--%EB%-F%AC-medium%C-%A-term%--scheduler-%--%-A%--%EB%A-%--%EB%AA%A-%EB%A-%AC%EC%--%--%--%EC%A-%--%EC%-E%AC%EB%--%-C%--%ED%--%--%EB%A-%-C%EC%--%B-%EC%-A%A-%--%EC%--%--%--%EA%B-%--%EB%A-%AC)

- **장기 스케줄러**
  - 새로운 프로세스가 들어올 때, 어떤 프로세스를 준비큐에 넣어줄 지 결정하는 역할을 하는 스케줄러 입니다.
  - 상대적으로 많이 호출되지 않으며, 처리 속도가 느리다는 특징이 있습니다.
- **단기 스케줄러**
  - 준비 상태인 프로세스 중에서 어떤 프로세스를 CPU에 할당할 지 정해주는 스케줄러 입니다.
  - 실제 스케줄러라고 하면 단기 프로젝트라고 의미합니다.
  - 매우 빠른 속도로 처리가 되어야 하며 자주 호출됩니다.
- **중기 스케줄러**
  - 메모리에 적재될 프로세스의 수를 동적으로 할당하고 관리하는 역할을 하는 스케줄러 입니다.
  - 만약 모든 프로세스에 메모리를 할당하게 되면 프로세스당 가질 수 있는 메모리는 적어지기에 성능이 저하되고 메모리가 부족한 문제가 발생할 수 있습니다.
  - 이를 위해 특정 프로세스의 메모리 내용을 통째로 가져와 디스크 스왑 영역에 저장하기도 하는데 이를 스왑아웃이라고 합니다.
  - 중기 스케줄러는 봉쇄 상태나 때에 따라서 준비 상태 중 문제가 발생하지 않을 프로세스에 대해서 스왑아웃과 반대로 스왑인을 통해 프로세스의 수를 관리하고 메모리를 확보합니다.
  - 스왑 아웃이 되면 `중지 -> 중지 준비`, `봉쇄 -> 봉쇄 중지` 상태로 표현합니다.

### 현대 OS에는 단기, 중기, 장기 스케쥴러를 모두 사용하고 있나요?
> [참고 자료](https://hojunking.tistory.com/52)

- 가상 메모리 관리가 발달하면서 장기 스케줄러의 경우, 필요성이 낮아져 사용하지 않는 추세라고 할 수 있습니다.
- 가상 메모리 관리를 통해 프로세스에 대한 메모리 할당에 제한이 없어지면서 프로세스가 생성되면 자동으로 메모리를 할당하게 됩니다.
- 또한 중기 스케줄러도 가상 메모리 관리로 필요한 데이터만 메모리로 로드되기 때문에 중요성이 떨어지는 부분도 있습니다.

> **가상 메모리 관리**: 프로그램이 CPU에 의해 실제로 사용되는 부분만 메모리에 로드하고 사용하지 않는 부분은 디스크에서 관리하는 방식

### 프로세스의 스케쥴링 상태에 대해 설명해 주세요.
![](https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FwJUeg%2FbtqBPXtRb0w%2FVS5WQD5vvl05WzUxHE05IK%2Fimg.png)

1. 생성 (New): 프로세스가 생성되었지만 아직 운영체제에 의해 초기화되거나 시작되기 전의 상태입니다.
2. 준비 (Ready): 프로세스가 실행을 위해 모든 준비가 완료되었으며, CPU를 할당받기를 기다리는 상태입니다. 단기 스케줄러에 의해 다음에 실행될 프로세스들 중 하나로 선택될 수 있습니다.
3. 실행 (Running): 프로세스가 현재 CPU에서 실행되고 있는 상태입니다. 한 번에 하나의 프로세스만이 실행될 수 있습니다.
4. 차단 (Blocked 또는 Waiting): 프로세스가 특정 이벤트가 발생하기를 기다리거나, 예를 들어 입출력 완료와 같은 외부 이벤트를 기다리며 일시 중단된 상태입니다. 이벤트가 발생하면 프로세스는 준비 상태로 돌아갈 수 있습니다.
5. 종료 (Terminated): 프로세스가 실행을 완료하거나 종료 요청을 받아서 종료된 상태입니다. 종료된 프로세스는 시스템에서 완전히 제거됩니다.

### preemptive/non-preemptive 에서 존재할 수 없는 상태가 있을까요?
> [참고 자료](https://peonyf.tistory.com/entry/CPU-Scheduler)

- preemptive : 현재 다른 프로세스가 실행중일지라도 이룰 중단하고 다른 프로세스가 CPU를 점유할 수 있는 방식
- non-preemptive : 현재 실행중인 프로세스가 종료될 때까지 다른 프로세스가 중간에 CPU를 가로챌 수 없는 방식

이와 같은 내용을 고려했을 때, 상태는 모드 가져갈 수 있습니다.
하지만 블록 상태로 넘어갔을 때, 선점의 경우는 다시 실행상태로 넘어갈 수 있고 

### Memory가 부족할 경우, Process는 어떠한 상태로 변화할까요?
아래와 같이 상태가 변할 수 있습니다.
- Blocked : 메모리가 확보되고 다시 프로세스가 동작할 수 있을 때까지 대기 상태로 변경할 수 있습니다.
- Terminated : 더 이상 실행이 불가능하고 판단하고 강제 종료시킬 수 있습니다.
- Swapping : 스왑 아웃을 통해 해당 프로세스의 메모리를 디스크의 스왑 영역으로 옮겨서 해결할 수 있습니다.

## 6. 컨텍스트 스위칭 시에는 어떤 일들이 일어나나요?
1. **컨텍스트 스위칭 원인 발생** : 여러 원인 중 하나가 발생하면 컨텍스트 스위칭이 발생합니다.
2. **커널 모드 전환**
3. **현재 프로세스 작업 상태를 저장** : 기존에 작업하던 프로세스의 레지스터 상태, 메모리 위치, PC 등의 중요한 정보를 PCB에 저장합니다. 
4. **다음 작업을 선택** : 다음에 실행한 프로세스를 선정합니다. 
5. **선택한 작업 내용을 복원** : 선정된 프로세스의 작업 내용을 PCB에서 확인하고 주요 정보들을 복구합니다.
6. **사용자 모드 전환**
7. **작업 실행** : 복구된 상태에서 작업을 실행합니다.

### 프로세스와 쓰레드는 컨텍스트 스위칭이 발생했을 때 어떤 차이가 있을까요?
- 프로세스의 경우, 다른 프로세스와의 공유 데이터가 없으므로 컨텍스트 스위칭 발생 시 많은 부분을 변경해야 합니다.
- 이전 프로세스가 쌓아놓은 데이터를 모두 제거하고 새로운 작업 환경을 만들어야 한다는 의미입니다.
- 하지만 쓰레드의 경우, 프로세스 내에서 공유하는 메모리가 존재하므로 상대적으로 더 적은 오버헤드로 스위칭이 가능하며 속도가 빠를 수 있습니다.

> 그렇다면 쓰레드의 컨텍스트 스위칭이 발생하면 CPU에선 바뀌는 지점이 없는건가?
> - 아닙니다.
> - 쓰레드가 다음 실행한 명령어 주소를 가진 PC나 쓰레드의 스택 상태를 가르키는 스택 포인터와 같은 데이터들이 변경되므로 CPU 측면에서도 차이가 발생합니다.

### 컨텍스트 스위칭이 발생할 때, 기존의 프로세스 정보는 커널스택에 어떠한 형식으로 저장되나요?

> PCB 정보 포인터만 추가된다?
> - 레지스터 값 저장, 상태 프래임 저장..?

### 컨텍스트 스위칭은 언제 일어날까요?
> [참고 자료](https://applefarm.tistory.com/105)

1. I/O interrupt
2. CPU 사용시간 만료
3. 자식 프로세스 Fork
4. 인터럽트 처리를 기다릴 때

> HW 인터럽트, SW 인터럽트, 외부 인터럽트, 내부 인터럽트 별로 구분해 볼 수도 있겠다.

## 7. 프로세스 스케줄링 알고리즘에는 어떤 것들이 있나요?
1. **선입선처리 스케줄링(FIFO : First In First Out, FCFS: First Come First Served)**
   - 말 그대로 먼저 들어온 프로세스를 먼저 처리하고 그 다음 프로세스들은 대기하는 방식입니다.
   - 단순한 스케줄링으로 구현이 쉽고 모든 프로세스가 동작할 수 있습니다.
   - 다만 작업이 단순한 프로세스여도 대기시간은 앞 프로세스로 인해 길어질 수 있습니다.(비효율적)
2. **최소 작업 우선 스케줄링(Shortest Job First)**
   - 작업 소요 시간이 가장 짧은 작업을 우선으로 처리하는 방식입니다.
   - 선입선처리 방식에서 대기시간에 대한 단점을 보안하고 선점이 가능한 구조로 동작합니다.
   - 하지만 작업시간이 긴 작업의 경우는 우선순위가 계속 밀려 기아가 발생할 수 있습니다.
3. 우선 순위 스케줄링(Priority)
   - 우선순위를 부여하고 우선순위가 높은 프로세스부터 처리하는 방식입니다.
   - 중요한 문제부터 처리해 효율성을 가져올 수 있습니다.
   - SJF와 동일하게 기아 문제가 발생할 수 있지만 에이징 기법을 통해 대기 시간이 길어지면 에이지를 부여해 우선순위를 높여줄 수 있습니다.
4. 라운드 로빈(Round Robin)
   - 작은 단위의 시간 할당량(Time-Slice)를 정의하고 그 시간 만큼 처리하고 다음 작업으로 이동하는 방식입니다.
   - 이를 통해 평균 대기 시간은 다른 방식에 비해 줄어들 수 있습니다.
   - 하지만 상대으로 time-slice가 작다면 잦은 Context Switching으로 더 큰 비용이 발생할 수 있습니다.

### RR을 사용할 때, Time Slice에 따른 trade-off를 설명해 주세요.
- Time Slice가 작을 경우
  - 모든 데이터들을 처리하는데 공정하게 처리하며 정해진 시간 동안 빠르게 분활해 처리해주기 때문에 빠른 응답속도를 가질 수 있습니다.
  - 하지만 잦은 변경으로 Context Switching이 자주 발생히 비용적인 부담을 가지게 됩니다.
- Time Slice가 높을 경우
  - Context Switching은 거의 일어나지 않아 비용적으로 부담을 없습니다.
  - 하지만 FCFS 방식과 크게 다르지 않은 형태로 동작하게 됩니다. 이는 대기시간이 길어져 처리 시간도 느려진다는 의미를 가집니다.

### 싱글 스레드 CPU 에서 상시로 돌아가야 하는 프로세스가 있다면, 어떤 스케쥴링 알고리즘을 사용하는 것이 좋을까요? 또 왜 그럴까요?
- 개인적인 의견으로 상시로 돌아가야 하는 프로세스라면 일정한 주기로 꼭 처리되어야 할 가능성이 있다고 생각이 됩니다.
- 그럴 경우에는 처리가 완전히 되어야 하기 때문에 기아 문제가 발생하는 것을 방지해야 하는 목적으로 FCFS를 선택해볼 수 있을 것 같습니다.
- 하지만 처리 시간이 길어져 다른 프로세스에 영향을 준다면 RR을 사용해 응답시간을 최소화해볼 수 있을 것 같습니다.
- 우선순위 스케줄러도 적합할 수 있다.

> 리얼 타임 스케줄링을 의미하는 것이라면?

### 동시성과 병렬성의 차이에 대해 설명해 주세요.
> [참고 자료](https://sas-study.tistory.com/446)

- **동시성**
  - 여러 작업을 동시에 처리하는 것처럼 보이지만 사실 여러 작업을 짧은 시간동안 번갈아가면서 반복 작업을 해 동시에 처리되는 것처럼 보이게 하는 개념입니다.
  - 이는 단일 코어에서 하나의 프로세스를 처리하는데 여러 쓰레로 동작을 구현할 때 적용될 수 있습니다.
- **병럴성**
  - 실제로 독립적인 환경에서 각각의 프로세스가 동시에 처리되는 것을 의미합니다.
  - 이는 멀티 코어 환경에서 적용이 가능한 개념입니다.

### 타 스케쥴러와 비교하여, Multi-level Feedback Queue는 어떤 문제점들을 해결한다고 볼 수 있을까요?
> [참고 자료](https://devforyou.tistory.com/73)
- MLFQ의 경우, 우선순위에 따른 큐를 여러개 두고 아래와 같은 규칙을 통해 동작하는 스케줄러라고 할 수 있습니다.
  ![](https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FNJnrd%2FbtrzAVZbm5M%2FjtVcDKVkQ81izMTClcXqR1%2Fimg.png)
- 이러한 규칙 중 5번을 지키기 위해 일정 주기가 되면 낮은 우선 순위에 있는 프로세스들을 상향 조정하게 되고 이는 boost 기능이라고 합니다.
- 즉, 기아 문제로 남아있을 뻔한 프로세스들에게 일정 주기 만큼 우선순위를 높혀줌으로써 실행될 수 있는 가능성을 높혀준다는 의미입니다.
- 이를 통해 기아 문제에 대해서 조금 더 해결책을 내놓은 스케줄러라고 할 수 있습니다.

### FIFO 스케쥴러는 정말 쓸모가 없는 친구일까요? 어떤 시나리오에 사용하면 좋을까요?
- 아무래도 동시성에 대한 중요도가 높은 경우가 대다수이고 처리 속도를 높여줄 만큼 하드웨어적인 지원이 가능한 경우가 많기에 FIFO에 대한 사용이 줄어들 수 있지만
- 안정적이고 단순한 구조로 처리가 가능하다라는 점에선 강점을 가지고 있다고 생각합니다.
  - 기아 문제 발생 없이 꼭 처리되어야 하며 처리 시간이 다른 작업에 영향을 주지 않는 정도인 경우
  - 그리고 우선순위를 정하는 기준이 모호하거나 필요성이 떨어지는 경우
  - 간단한 스케줄링을 요구하는 경우
  - 가벼운 작업을 진행하는 경우 굳이 다른 알고리즘을 쓸 필요가 없다고 생각합니다.
  - 하지만 작업이 커지고 확장됨에 따라 변경에 대한 고려를 해야합니다.

### 유저 스레드와 커널 스레드의 스케쥴링 알고리즘은 똑같을까요?
- 유저 스레드
  - 응용 프로그램 내에서 관리되고 동작하는 스레드를 의미하며 런타임 라이브러리에서 관리가 됩니다.
  - 즉, 응용 프로그램에서 관리되는 스레드를 의미합니다.
- 커널 스레드
  - 운영 체제에서 관리되는 스레드입니다.

- 다른 점은?
  - 커널 스레드에서는 멀티 코어 환경과 같은 병렬성과 동시성을 고려해 위와 같은 복잡한 알고리즘들(MLQS, CFS)을 사용하는 경우가 많습니다.
  - 이에 반해 유저 스레드는 단순한 형태의 알고리즘을 사용하는 경우가 많습니다. 또는 직접 설계도 가능합니다.

> [CFS](https://hasensprung.tistory.com/178)
> - Complitely Fair Scheduler의 약자
> - CPU에 공정한 할당 및 사용을 목표로 구현된 알고리즘
> - 프로세스 별로 부여된 Time slice를 모두 소진한 경우, 다른 프로세스들이 Time Slice를 소진할 때까지 CPU 할당을 받지 못하게 구현
> - 이를 통해 모든 프로세스들이 공정한 CPU 사용을 하도록 동작
